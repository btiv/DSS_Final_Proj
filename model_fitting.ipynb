{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79e25537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "73138b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a list of 5 countries to start with abundant data\n",
    "countries = ['Australia', 'Canada', 'Spain', 'Norway', 'Brazil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d87af2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_percent_change_features(country_list, start_date, train_date, test_date):\n",
    "    def percent_change(new, original):\n",
    "        return (new - original) / original\n",
    "    \n",
    "    # store dataframes in lists\n",
    "    df_list = []\n",
    "\n",
    "    for country in countries:\n",
    "        country_df = pd.read_csv(f'{country}_biodiversity_research.csv')\n",
    "        country_df = country_df[country_df['Country Specific Authors'] > 0]\n",
    "        country_df = country_df.reset_index(drop=True)\n",
    "\n",
    "        # get papers from 1998 and onwards\n",
    "        country_df = country_df[country_df['Publication Year'] >= 1998]\n",
    "        country_df = country_df.reset_index(drop=True)\n",
    "        df_list.append(country_df)\n",
    "\n",
    "    country_train = []\n",
    "    country_test = []\n",
    "\n",
    "    for country_data in df_list:\n",
    "        train_data = pd.DataFrame(dict({'Year': np.zeros(train_date - 1998 + 1), 'Paper Volume': np.zeros(train_date - 1998 + 1), 'Mean Adj. Citations': np.zeros(train_date - 1998 + 1), 'Mean Authors': np.zeros(train_date - 1998 + 1), 'Mean Orgs': np.zeros(train_date - 1998 + 1)}))\n",
    "        test_data = pd.DataFrame(dict({'Year': np.zeros(test_date - train_date), 'Paper Volume': np.zeros(test_date - train_date), 'Mean Adj. Citations': np.zeros(test_date - train_date), 'Mean Authors': np.zeros(test_date - train_date), 'Mean Orgs': np.zeros(test_date - train_date)}))\n",
    "        for date in range(1998, test_date + 1):\n",
    "            year_data = country_data[country_data['Publication Year'] == date]\n",
    "            year_data = year_data.reset_index(drop=True)\n",
    "\n",
    "            if date <= train_date:\n",
    "                train_data.iloc[date - 1998] = [date, len(year_data), year_data['Adjusted Citations'].mean(), year_data['Country Specific Authors'].mean(), year_data['Country Specific Orgs'].mean()]\n",
    "            else:\n",
    "                test_data.iloc[date - train_date - 1] = [date, len(year_data), year_data['Adjusted Citations'].mean(), year_data['Country Specific Authors'].mean(), year_data['Country Specific Orgs'].mean()]\n",
    "\n",
    "        country_train.append(train_data)\n",
    "        country_test.append(test_data)\n",
    "    \n",
    "    protected_df = pd.read_csv('protected_land_cleaned.csv')\n",
    "    \n",
    "    # now compute the percent changes starting from start_date (i.e. can start analysis in start_date + 1)\n",
    "    \n",
    "    percent_change_train = []\n",
    "    percent_change_test = []\n",
    "    percent_change_protected_test = []\n",
    "    percent_change_protected_train = []\n",
    "\n",
    "    for train_df in country_train:\n",
    "        percent_train = pd.DataFrame(dict({'Change Volume': np.zeros(train_date - start_date), 'Change Citations': np.zeros(train_date - start_date), 'Change Authors': np.zeros(train_date - start_date), 'Change Orgs': np.zeros(train_date - start_date)}))\n",
    "        for i in range(train_date - start_date):\n",
    "            percent_train.iloc[i] = [percent_change(train_df.iloc[10 + i]['Paper Volume'], train_df.iloc[9 + i]['Paper Volume']), percent_change(train_df.iloc[10 + i]['Mean Adj. Citations'], train_df.iloc[9 + i]['Mean Adj. Citations']), percent_change(train_df.iloc[10 + i]['Mean Authors'], train_df.iloc[9 + i]['Mean Authors']), percent_change(train_df.iloc[10 + i]['Mean Orgs'], train_df.iloc[9 + i]['Mean Orgs'])]\n",
    "        percent_change_train.append(percent_train)\n",
    "\n",
    "    for test_df in country_test:    \n",
    "        percent_test = pd.DataFrame(dict({'Change Volume': np.zeros(test_date - train_date - 1), 'Change Citations': np.zeros(test_date - train_date - 1), 'Change Authors': np.zeros(test_date - train_date - 1), 'Change Orgs': np.zeros(test_date - train_date - 1)}))\n",
    "        for i in range(test_date - train_date - 1):\n",
    "            percent_test.iloc[i] = [percent_change(test_df.iloc[1 + i]['Paper Volume'], test_df.iloc[0 + i]['Paper Volume']), percent_change(test_df.iloc[1 + i]['Mean Adj. Citations'], test_df.iloc[0 + i]['Mean Adj. Citations']), percent_change(test_df.iloc[1 + i]['Mean Authors'], test_df.iloc[0 + i]['Mean Authors']), percent_change(test_df.iloc[1 + i]['Mean Orgs'], test_df.iloc[0 + i]['Mean Orgs'])]\n",
    "        percent_change_test.append(percent_test)\n",
    "\n",
    "    for country in countries:\n",
    "        country_protected = protected_df[protected_df['Country'] == country]\n",
    "        country_protected = country_protected[country_protected['Year'] >= start_date]\n",
    "        country_protected = country_protected[country_protected['Year'] <= test_date]\n",
    "        country_protected = country_protected.reset_index(drop=True)\n",
    "\n",
    "        protect_change_train = pd.DataFrame(dict({'Change Protected Percent': np.zeros(train_date - start_date)}))\n",
    "        for i in range(train_date - start_date):\n",
    "            protect_change_train.iloc[i] = [percent_change(country_protected.iloc[1 + i]['Value'], country_protected.iloc[0 + i]['Value'])]\n",
    "        percent_change_protected_train.append(protect_change_train)\n",
    "\n",
    "        protect_change_test = pd.DataFrame(dict({'Change Protected Percent': np.zeros(test_date - train_date - 1)}))\n",
    "        for i in range(test_date - train_date - 1):\n",
    "            protect_change_test.iloc[i] = [percent_change(country_protected.iloc[train_date - start_date + 2 + i]['Value'], country_protected.iloc[train_date - start_date + 1 + i]['Value'])]\n",
    "        percent_change_protected_test.append(protect_change_test)\n",
    "        \n",
    "    return percent_change_train, percent_change_test, percent_change_protected_train, percent_change_protected_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5661f590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\btiv\\AppData\\Local\\Temp/ipykernel_37148/2007696634.py:9: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  country_df = pd.read_csv(f'{country}_biodiversity_research.csv')\n",
      "C:\\Users\\btiv\\AppData\\Local\\Temp/ipykernel_37148/2007696634.py:9: DtypeWarning: Columns (11,15,50,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  country_df = pd.read_csv(f'{country}_biodiversity_research.csv')\n",
      "C:\\Users\\btiv\\AppData\\Local\\Temp/ipykernel_37148/2007696634.py:9: DtypeWarning: Columns (15,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  country_df = pd.read_csv(f'{country}_biodiversity_research.csv')\n",
      "C:\\Users\\btiv\\AppData\\Local\\Temp/ipykernel_37148/2007696634.py:9: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  country_df = pd.read_csv(f'{country}_biodiversity_research.csv')\n"
     ]
    }
   ],
   "source": [
    "X_train_list, X_test_list, y_train_list, y_test_list = compute_percent_change_features(countries, 2007, 2015, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a6384e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Change Volume</th>\n",
       "      <th>Change Citations</th>\n",
       "      <th>Change Authors</th>\n",
       "      <th>Change Orgs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.142857</td>\n",
       "      <td>0.037437</td>\n",
       "      <td>-0.105556</td>\n",
       "      <td>0.010163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.680556</td>\n",
       "      <td>-0.123062</td>\n",
       "      <td>0.091163</td>\n",
       "      <td>-0.011058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.206612</td>\n",
       "      <td>0.430216</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.055859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.106164</td>\n",
       "      <td>-0.069008</td>\n",
       "      <td>0.013509</td>\n",
       "      <td>0.078415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.139319</td>\n",
       "      <td>0.027436</td>\n",
       "      <td>0.084505</td>\n",
       "      <td>0.076754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.214674</td>\n",
       "      <td>0.047168</td>\n",
       "      <td>-0.101331</td>\n",
       "      <td>-0.115613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.228188</td>\n",
       "      <td>0.013154</td>\n",
       "      <td>0.077536</td>\n",
       "      <td>0.048479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.176685</td>\n",
       "      <td>-0.118305</td>\n",
       "      <td>0.112391</td>\n",
       "      <td>0.089999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Change Volume  Change Citations  Change Authors  Change Orgs\n",
       "0       4.142857          0.037437       -0.105556     0.010163\n",
       "1       0.680556         -0.123062        0.091163    -0.011058\n",
       "2       0.206612          0.430216        0.002149     0.055859\n",
       "3       0.106164         -0.069008        0.013509     0.078415\n",
       "4       0.139319          0.027436        0.084505     0.076754\n",
       "5       0.214674          0.047168       -0.101331    -0.115613\n",
       "6       0.228188          0.013154        0.077536     0.048479\n",
       "7       0.176685         -0.118305        0.112391     0.089999"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "09b7ae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_MSE(y_pred, y_true):\n",
    "    return (1/len(y_pred))*sum(((np.array(y_pred)-np.array(y_true))**2))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a2ed3ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012589574822727679"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a simple Linear Regression Model for Country 0 (Australia)\n",
    "\n",
    "regr = LinearRegression()\n",
    "regr = regr.fit(X_train_list[0], y_train_list[0])\n",
    "\n",
    "# get MSE on the test set\n",
    "calc_MSE(regr.predict(X_test_list[0]), y_test_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aa4cb1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Degree 1 polynomial: 0.012589574822727677\n",
      "MSE of Degree 2 polynomial: 0.02852839058164885\n",
      "MSE of Degree 3 polynomial: 0.01062191798749243\n",
      "MSE of Degree 4 polynomial: 0.013470092861679044\n",
      "MSE of Degree 5 polynomial: 0.013034545015961907\n",
      "MSE of Degree 6 polynomial: 0.013479253846113166\n",
      "MSE of Degree 7 polynomial: 0.013506837887267581\n",
      "MSE of Degree 8 polynomial: 0.013582727764682495\n",
      "MSE of Degree 9 polynomial: 0.013599283226812836\n",
      "MSE of Degree 10 polynomial: 0.013613139260290964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# choose polynomial order than minimizes MSE on test set\n",
    "degrees = list(range(1, 11))\n",
    "\n",
    "for degree in degrees:\n",
    "    # polynomial feature transform\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X_poly_train = poly.fit_transform(X_train_list[0])\n",
    "    X_poly_test = poly.transform(X_test_list[0])\n",
    "\n",
    "    # fit a model with the new polynomial features\n",
    "    poly_regr = LinearRegression()\n",
    "    poly_regr = poly_regr.fit(X_poly_train, y_train_list[0])\n",
    "\n",
    "    # get MSE on test set\n",
    "    print(f'MSE of Degree {degree} polynomial: {calc_MSE(poly_regr.predict(X_poly_test), y_test_list[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a80440b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      " [[ 0.03921306]\n",
      " [ 0.06903876]\n",
      " [ 0.08466675]\n",
      " [ 0.03615381]\n",
      " [-0.20262732]]\n",
      "\n",
      "Actual Values:\n",
      " 0    0.013382\n",
      "1    0.005280\n",
      "2    0.000147\n",
      "3    0.049414\n",
      "4    0.000000\n",
      "Name: Change Protected Percent, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# train the optimal degree 3 polynomial\n",
    "poly = PolynomialFeatures(3)\n",
    "X_poly_train = poly.fit_transform(X_train_list[0])\n",
    "X_poly_test = poly.transform(X_test_list[0])\n",
    "\n",
    "# fit a model with the new polynomial features\n",
    "poly_regr = LinearRegression()\n",
    "poly_regr = poly_regr.fit(X_poly_train, y_train_list[0])\n",
    "\n",
    "print('Predictions:\\n', poly_regr.predict(X_poly_test))\n",
    "print('\\nActual Values:\\n', y_test_list[0]['Change Protected Percent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53878288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next steps: Add latent variables to X_train data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
